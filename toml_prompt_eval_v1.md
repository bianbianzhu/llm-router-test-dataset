# 输入

无

# 输出：

1. 更新过后的意图定义文件 <意图种类名称>.md （可能是多个）

**注意:**
完成每一步后，都必须更新 progress.md

## 步骤 0: 生成笔记

- 仿照例子和当前任务生成笔记 progress.md

## 步骤 1: 生成测试结果报告

### **目标**

任务是与用户交互，认需要处理的数据集，然后使用 `pnpm run eval:report` 命令为该数据集生成测试报告，并根据执行结果进行相应处理。

---

- **核心命令**：

```bash
pnpm run eval:report <datasetName> [--concurrency <concurrency>]
```

**参数说明:**

- **`<datasetName>` (必需):** LangSmith 中目标数据集的名称。
- **`--concurrency` / `-c` (可选):**
  - **默认值:** `low`。
  - **可选值:** `none`, `low`, `high`。
  - **使用场景:** 仅在处理大数据集（例如，超过 1000 个样本）时，才需考虑使用 `high`。
- **`--prefix` / `-p` (忽略):** 此参数由系统自动生成，你无需关心或提供。
- **帮助命令:** 如果对参数不确定，可执行 `pnpm run eval:report --help` 查看最新用法。

### **工作流程**：

请严格按照以下步骤执行：

#### **1: 确认目标数据集**

你的首要任务是明确用户想要为哪个数据集生成报告。

1.  **基于上下文推断:**

    - 检查最近的对话历史，寻找最近被提及或创建的数据集名称。
    - **过滤规则:** 忽略名称中包含 `loose` 关键词的数据集。
    - 向用户提议：`“是否要为最近的数据集 '...' 生成测试报告？”`
    - 如果用户同意，直接进入 **步骤 2**。

2.  **让用户选择:**
    - 如果上下文没有可用信息，或用户拒绝了你的提议，请执行以下操作：
    - 运行命令 `pnpm run langsmith:basic --operation list-datasets` 获取所有可用数据集。
    - 将返回的数据集列表 **按时间倒序（最新的在前）** 展示给用户。
    - 请用户从列表中选择一个。

#### **2: 验证并执行**

1.  **获取数据集大小 (验证):**

    - 在执行生成报告的命令前，使用 `pnpm run langsmith:basic --operation list-datasets` 确认用户选定的数据集确实存在，并记下其样本数量（size）。

2.  **构建并执行命令:**
    - 基于用户选择的 `<datasetName>` 构建命令。
    - **决策:** 如果数据集样本数量大于 1000，使用 `--concurrency high` 以加快处理速度。否则，使用默认并发即可。
    - 执行最终构建的命令。

#### **3: 监控与处理结果**

1.  **监控终端输出**，分析执行结果。

2.  **成功处理:**

    - **识别标志:** 终端输出包含 `Report generated successfully` 类似信息，并提供报告文件的路径。
    - **记录进度:** 在 `progress.md` 文件中追加一条新记录，格式如下：
      ```markdown
      - [报告生成成功] 数据集: `<datasetName>`, 报告路径: `<path/to/report.html>`
      ```
    - **通知用户:** 告知用户报告已成功生成，并提供文件路径。

3.  **失败处理:**
    - **识别标志:** 命令以非零状态码退出，或终端输出明确的错误信息（如 `Error:`, `Failed to...`）。
    - **报告错误:** 向用户清晰地展示 **完整的、未经修改的** 终端错误日志。
    - **请求指示:** 询问用户接下来需要如何操作（例如，重试或放弃）。

## 步骤 2: 根据测试报告优化意图定义

### **目标**

任务是分析上一步生成的测试报告，判断是否需要优化意图（Intent）的定义提示词。如果需要，你将根据报告中的失败案例生成优化后的定义，并更新对应的文件。

### **前置条件**

- 你已经获得了上一步生成的报告文件路径。

---

### **工作流程**

请严格按照以下步骤执行：

#### **1: 读取并解析报告**

1.  **读取文件**: 读取并加载你获得路径的报告文件（Markdown 格式）的全部内容。
2.  **提取关键信息**: 从文件内容中解析并提取以下两个核心部分：
    - **基准 (Benchmark)**: 定位到报告中的基准测试分数（通常是一个百分比，如 `95%`）。
    - **失败案例 (Failure Cases)**: 逐一分析失败案例列表，统计每个意图 (`<intent>`) 出现的失败次数。

#### **2: 决策：是否需要优化**

根据上一步提取的信息，应用以下决策规则：

- **情况 A: 无需优化**

  - **条件**:
    1.  基准分数 **高于 95%**。
    2.  **并且** 失败案例分布广泛（即：没有任何一个意图的失败次数超过总失败案例的 50%）。
  - **操作**:
    1.  向用户报告：“测试报告的基准为 `[具体分数]`，且失败案例未集中在特定意图上，目前无需优化。”
    2.  **任务结束**。

- **情况 B: 建议优化**
  - **条件**:
    1.  基准分数 **低于或等于 95%**。
    2.  **或者** 失败案例高度集中（即：某一个意图的失败次数占总失败案例的 50% 以上）。
  - **操作**:
    1.  向用户解释原因，例如：“检测到基准分数为 `[具体分数]`，或发现失败案例主要集中在 `[意图名称]` 上。”
    2.  提问用户：“**是否需要我根据报告中的失败案例来优化相关的意图定义？**”
    3.  等待用户确认。如果用户拒绝，则任务结束。

#### **3: 生成优化后的意图定义**

- **触发条件**: 用户同意优化。
- **执行**:
  1.  将 **完整的报告文件内容** 作为你的上下文和知识库。
  2.  **核心任务**: 聚焦于报告中失败次数最多的意图。分析相关的失败案例，思考为什么模型会混淆或判断错误。然后，**重新编写** 该意图的定义，使其描述更精确、边界更清晰、更能与其它意图区分开。
  3.  **输出**: 生成优化后的新意图定义文本。

#### **4: 更新本地文件**

1.  **定位文件**:

    - 根据被优化的意图名称（例如 `order_ticket`），在 `intents/` 目录下找到对应的意图定义文件（例如 `intents/order_ticket.md`）。
    - **重要约束**: 绝对不能修改任何以 `_loose.md` 结尾的文件。

2.  **执行更新**:

    - 用你在**步骤 3**中生成的新定义，**完全覆盖**目标文件中的旧内容。

3.  **记录与反馈**:
    - **更新进度**: 在 `progress.md` 文件中追加一条记录，格式如下：
      ```markdown
      - [意图优化] 已成功更新意图 '[意图名称]' 的定义文件: `intents/[文件名].md`
      ```
    - **通知用户**: 清晰地告知用户操作结果。
      - **成功**: `“已成功更新意图 '[意图名称]' 的定义。文件路径: 'intents/[文件名].md'”`
      - **失败**: 如果在文件写入过程中发生任何错误，应立即报告：`“错误：在更新 'intents/[文件名].md' 时发生问题。错误详情：[终端错误信息]”`

## 步骤 3: 意图优化迭代循环 (Loop)

### **目标**

管理一个迭代优化循环。此循环的目标是通过重复 **生成报告 (步骤 1)** 和 **优化意图 (步骤 2)** 的过程，将测试报告中的基准分数提升至 **95% 以上**。整个过程由用户控制，每一轮新的优化都必须得到用户的明确同意。

### **核心原则**

你的工作模式是一个循环：
**生成新报告 → 评估基准 → 获取用户同意 → 优化意图 → (循环)**

### **触发条件**

此工作流程在 **步骤 2（根据报告优化意图定义）** 完成一次后自动开始。你已经生成了第一份优化后的意图定义，并需要评估其效果。

---

### **工作流程**

请严格按照以下步骤执行：

#### **1: 评估当前状态并决策**

1.  你手中应该有最新一次 `eval:report` 生成的报告。
2.  从该报告中解析出 **当前的基准分数**。
3.  应用以下决策规则：

    - **IF 基准 > 95% (成功终止):**

      1.  **祝贺用户**: “太棒了！经过优化，当前测试基准已达到 **`[具体分数]`**，超过了 95%的目标。”
      2.  **更新进度**: 在 `progress.md` 中追加最终成功记录：
          ```markdown
          - [优化完成] 最终基准: [具体分数] > 95%. 优化循环结束。
          ```
      3.  **任务结束**。

    - **IF 基准 <= 95% (进入决策点):**
      1.  继续执行 **步骤 2**。

#### **2: 获取用户同意以继续**

1.  **报告现状**: 清晰地向用户展示当前的情况。

    > **示例对话**: “我们完成了一轮优化。当前的测试基准是 **`[具体分数]`**，尚未达到 95%的目标。**是否要开始新一轮的优化？**”

2.  **等待用户指令**:
    - **IF 用户同意 (例如 "是", "继续", "好的"):**
      - 进入 **步骤 3**，开始新的优化循环。
    - **IF 用户拒绝 (例如 "否", "停止", "就这样吧"):**
      - **确认停止**: “好的，我们将停止在当前基准 **`[具体分数]`**。优化循环已结束。”
      - **更新进度**: 在 `progress.md` 中追加记录：
        ```markdown
        - [优化暂停] 用户选择停止。最终基准: [具体分数]。
        ```
      - **任务结束**。

#### **3: 执行新一轮优化循环**

1.  **重新生成报告 (执行步骤 1 的核心)**

    - 告知用户：“好的，正在为数据集 `[数据集名称]` 重新生成测试报告以评估最新变更...”
    - 执行命令 `pnpm run eval:report <datasetName>`。**使用与之前完全相同的 `<datasetName>`**。
    - 等待命令执行成功并获取新的报告路径。

2.  **分析与优化 (执行步骤 2 的核心)**

    - 告知用户：“报告已生成，现在开始分析并准备下一次优化...”
    - 严格遵循 **“步骤 2: 根据测试报告优化意图定义”** 的完整工作流程：
      - 读取并解析新的报告。
      - 分析失败案例。
      - 生成优化后的意图定义。
      - 更新对应的意图文件 (`intents/*.md`)。

3.  **返回循环起点**
    - 当新的意图文件更新完成后，告知用户：“意图定义已更新。现在让我们再次评估效果。”
    - **回到本流程的 “步骤 1: 评估当前状态并决策”**，使用刚刚生成的新报告来检查最新的基准分数，从而开始下一次循环判断。
