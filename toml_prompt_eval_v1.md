# 输入

无

# 输出：

1. 更新过后的意图定义文件 <意图种类名称>.md （可能是多个）

**注意:**
完成每一步后，都必须更新 progress.md

## 步骤 0: 生成笔记

- 仿照例子和当前任务生成笔记 progress.md

## 步骤 1: 生成测试结果报告

### **目标**

任务是与用户交互，认需要处理的数据集，然后使用 `pnpm run eval:report` 命令为该数据集生成测试报告，并根据执行结果进行相应处理。

---

- **核心命令**：

```bash
pnpm run eval:report <datasetName> [--concurrency <concurrency>]
```

**参数说明:**

- **`<datasetName>` (必需):** LangSmith 中目标数据集的名称。
- **`--concurrency` / `-c` (可选):**
  - **默认值:** `low`。
  - **可选值:** `none`, `low`, `high`。
  - **使用场景:** 仅在处理大数据集（例如，超过 1000 个样本）时，才需考虑使用 `high`。
- **`--prefix` / `-p` (忽略):** 此参数由系统自动生成，你无需关心或提供。
- **帮助命令:** 如果对参数不确定，可执行 `pnpm run eval:report --help` 查看最新用法。

### **工作流程**：

请严格按照以下步骤执行：

#### **1: 确认目标数据集**

你的首要任务是明确用户想要为哪个数据集生成报告。

1.  **基于上下文推断:**

    - 检查最近的对话历史，寻找最近被提及或创建的数据集名称。
    - **过滤规则:** 忽略名称中包含 `loose` 关键词的数据集。
    - 向用户提议：`“是否要为最近的数据集 '...' 生成测试报告？”`
    - 如果用户同意，直接进入 **步骤 2**。

2.  **让用户选择:**
    - 如果上下文没有可用信息，或用户拒绝了你的提议，请执行以下操作：
    - 运行命令 `pnpm run langsmith:basic --operation list-datasets` 获取所有可用数据集。
    - 将返回的数据集列表 **按时间倒序（最新的在前）** 展示给用户。
    - 请用户从列表中选择一个。

#### **2: 验证并执行**

1.  **获取数据集大小 (验证):**

    - 在执行生成报告的命令前，使用 `pnpm run langsmith:basic --operation list-datasets` 确认用户选定的数据集确实存在，并记下其样本数量（size）。

2.  **构建并执行命令:**
    - 基于用户选择的 `<datasetName>` 构建命令。
    - **决策:** 如果数据集样本数量大于 1000，使用 `--concurrency high` 以加快处理速度。否则，使用默认并发即可。
    - 执行最终构建的命令。

#### **3: 监控与处理结果**

1.  **监控终端输出**，分析执行结果。

2.  **成功处理:**

    - **识别标志:** 终端输出包含 `Report generated successfully` 类似信息，并提供报告文件的路径。
    - **记录进度:** 在 `progress.md` 文件中追加一条新记录，格式如下：
      ```markdown
      - [报告生成成功] 数据集: `<datasetName>`, 报告路径: `<path/to/report.html>`
      ```
    - **通知用户:** 告知用户报告已成功生成，并提供文件路径。

3.  **失败处理:**
    - **识别标志:** 命令以非零状态码退出，或终端输出明确的错误信息（如 `Error:`, `Failed to...`）。
    - **报告错误:** 向用户清晰地展示 **完整的、未经修改的** 终端错误日志。
    - **请求指示:** 询问用户接下来需要如何操作（例如，重试或放弃）。

## 步骤 2: 根据测试报告优化意图定义\*\*

### **目标**

任务是分析上一步生成的测试报告，判断是否需要优化意图（Intent）的定义提示词。如果需要，你将根据报告中的失败案例生成优化后的定义，并更新对应的文件。

### **前置条件**

- 你已经获得了上一步生成的报告文件路径。

---

### **工作流程**

请严格按照以下步骤执行：

#### **1: 读取并解析报告**

1.  **读取文件**: 读取并加载你获得路径的报告文件（Markdown 格式）的全部内容。
2.  **提取关键信息**: 从文件内容中解析并提取以下两个核心部分：
    - **基准 (Benchmark)**: 定位到报告中的基准测试分数（通常是一个百分比，如 `95%`）。
    - **失败案例 (Failure Cases)**: 逐一分析失败案例列表，统计每个意图 (`<intent>`) 出现的失败次数。

#### **2: 决策：是否需要优化**

根据上一步提取的信息，应用以下决策规则：

- **情况 A: 无需优化**

  - **条件**:
    1.  基准分数 **高于 95%**。
    2.  **并且** 失败案例分布广泛（即：没有任何一个意图的失败次数超过总失败案例的 50%）。
  - **操作**:
    1.  向用户报告：“测试报告的基准为 `[具体分数]`，且失败案例未集中在特定意图上，目前无需优化。”
    2.  **任务结束**。

- **情况 B: 建议优化**
  - **条件**:
    1.  基准分数 **低于或等于 95%**。
    2.  **或者** 失败案例高度集中（即：某一个意图的失败次数占总失败案例的 50% 以上）。
  - **操作**:
    1.  向用户解释原因，例如：“检测到基准分数为 `[具体分数]`，或发现失败案例主要集中在 `[意图名称]` 上。”
    2.  提问用户：“**是否需要我根据报告中的失败案例来优化相关的意图定义？**”
    3.  等待用户确认。如果用户拒绝，则任务结束。

#### **3: 生成优化后的意图定义**

- **触发条件**: 用户同意优化。
- **执行**:
  1.  将 **完整的报告文件内容** 作为你的上下文和知识库。
  2.  **核心任务**: 聚焦于报告中失败次数最多的意图。分析相关的失败案例，思考为什么模型会混淆或判断错误。然后，**重新编写** 该意图的定义，使其描述更精确、边界更清晰、更能与其它意图区分开。
  3.  **输出**: 生成优化后的新意图定义文本。

#### **4: 更新本地文件**

1.  **定位文件**:

    - 根据被优化的意图名称（例如 `order_ticket`），在 `intents/` 目录下找到对应的意图定义文件（例如 `intents/order_ticket.md`）。
    - **重要约束**: 绝对不能修改任何以 `_loose.md` 结尾的文件。

2.  **执行更新**:

    - 用你在**步骤 3**中生成的新定义，**完全覆盖**目标文件中的旧内容。

3.  **记录与反馈**:
    - **更新进度**: 在 `progress.md` 文件中追加一条记录，格式如下：
      ```markdown
      - [意图优化] 已成功更新意图 '[意图名称]' 的定义文件: `intents/[文件名].md`
      ```
    - **通知用户**: 清晰地告知用户操作结果。
      - **成功**: `“已成功更新意图 '[意图名称]' 的定义。文件路径: 'intents/[文件名].md'”`
      - **失败**: 如果在文件写入过程中发生任何错误，应立即报告：`“错误：在更新 'intents/[文件名].md' 时发生问题。错误详情：[终端错误信息]”`
